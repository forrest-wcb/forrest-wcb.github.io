<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CUDA学习笔记</title>
      <link href="/2023/12/29/cuda/"/>
      <url>/2023/12/29/cuda/</url>
      
        <content type="html"><![CDATA[<h1>CUDA C/C++编程的学习</h1><p><strong>本文基于英伟达提供的线上自主学习课程</strong></p><p>加速计算正在取代 CPU 计算，成为最佳计算做法。加速计算带来的层出不穷的突破性进展、对加速应用程序日益增长的需求、轻松编写加速计算的编程规范以及支持加速计算的硬件的不断改进，所有这一切都在推动计算方式必然会过渡到加速计算。</p><h2 id="为GPU编写应用程序代码">为GPU编写应用程序代码</h2><p>以下是一个 <code>.cu</code> 文件（<code>.cu</code> 是 CUDA 加速程序的文件扩展名）。其中包含两个函数，第一个函数将在 CPU 上运行，第二个将在 GPU 上运行。请抽点时间找出这两个函数在定义方式和调用方式上的差异。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">CPUFunction</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This function is defined to run on the CPU.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">GPUFunction</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This function is defined to run on the GPU.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  CPUFunction();</span><br><span class="line"></span><br><span class="line">  GPUFunction&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是一些需要特别注意的重要代码行，以及加速计算中使用的一些其他常用术语：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">__global__ void GPUFunction()</span><br></pre></td></tr></table></figure><ul><li><code>__global__</code> 关键字表明以下函数将在 GPU 上运行并可<strong>全局</strong>调用，而在此种情况下，则指由 CPU 或 GPU 调用。</li><li>通常，我们将在 CPU 上执行的代码称为<strong>主机</strong>代码，而将在 GPU 上运行的代码称为<strong>设备</strong>代码。</li><li>注意返回类型为 <code>void</code>。使用 <code>__global__</code> 关键字定义的函数需要返回 <code>void</code> 类型。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GPUFunction&lt;&lt;&lt;1, 1&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure><ul><li>通常，当调用要在 GPU 上运行的函数时，我们将此种函数称为<strong>已启动</strong>的<strong>核函数</strong>。</li><li>启动核函数时，我们必须提供<strong>执行配置</strong>，即在向核函数传递任何预期参数之前使用 <code>&lt;&lt;&lt; ... &gt;&gt;&gt;</code> 语法完成的配置。</li><li>在宏观层面，程序员可通过执行配置为核函数启动指定<strong>线程层次结构</strong>，从而定义线程组（称为<strong>线程块</strong>）的数量，以及要在每个线程块中执行的<strong>线程</strong>数量。稍后将在本实验深入探讨执行配置，但现在请注意正在使用包含 <code>1</code> 线程（第二个配置参数）的 <code>1</code> 线程块（第一个执行配置参数）启动核函数。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cudaDeviceSynchronize();</span><br></pre></td></tr></table></figure><ul><li>与许多 C/C++ 代码不同，核函数启动方式为<strong>异步</strong>：CPU 代码将继续执行<em>而无需等待核函数完成启动</em>。</li><li>调用 CUDA 运行时提供的函数 <code>cudaDeviceSynchronize</code> 将导致主机 (CPU) 代码暂作等待，直至设备 (GPU) 代码执行完成，才能在 CPU 上恢复执行。</li></ul><h3 id="练习">练习</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">helloCPU</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Hello from the CPU.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">helloGPU</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Hello from the GPU.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">  helloCPU();</span><br><span class="line">    </span><br><span class="line">  helloGPU&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line"></span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上是对 nvidia所给例子<a href="http://dli-604a4aa51b37-99aaad.aws.labs.courses.nvidia.com/lab/edit/01-hello/01-hello-gpu.cu"><code>01-hello-gpu.cu</code></a> 的重构，运行结果为先后次序打印Hello from the CPU.和Hello from the GPU.</p><ul><li><p>从核函数定义中删除关键字 <code>__global__</code>。注意错误中的行号：您认为错误中的 \”configured\” 是什么意思？完成后，请替换 <code>__global__</code>。</p><p>报错a host function call cannot be configured。</p><p>未声明关键字_<em>global</em>_，函数不可被&lt;&lt;&lt;…&gt;&gt;&gt;配置</p></li><li><p>移除执行配置：您对 \”configured\” 的理解是否仍旧合理？完成后，请替换执行配置。</p><p>报错a __global__ function call must be configured。</p><p>启动核函数必须提供执行配置。</p></li><li><p>移除对 <code>cudaDeviceSynchronize</code> 的调用。在编译和运行代码之前，猜猜会发生什么情况，可以回顾一下核函数采取的是异步启动，且 <code>cudaDeviceSynchronize</code> 会使主机执行暂作等待，直至核函数执行完成后才会继续。完成后，请替换对 <code>cudaDeviceSynchronize</code> 的调用。</p><p>只打印Hello from the CPU.</p><p>核函数异步启动，CPU将继续执行而不会等待GPU执行完成</p></li><li><p>重构 <code>01-hello-gpu.cu</code>，以便 <code>Hello from the GPU</code> 在 <code>Hello from the CPU</code> <strong>之前</strong>打印。</p><p>将<code>helloGPU&lt;&lt;&lt;1,1&gt;&gt;&gt;();</code>及<code>cudaDeviceSynchronize();</code>移至helloCPU()前，main()如下</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">helloGPU&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">cudaDeviceSynchronize();</span><br><span class="line">helloCPU();</span><br></pre></td></tr></table></figure><p>cudaDeviceSynchronize();必须调至helloCPU前，若只改动helloGPU打印结果顺序不会变。</p></li><li><p>重构 <code>01-hello-gpu.cu</code>，以便 <code>Hello from the GPU</code> 打印<strong>两次</strong>，一次是在 <code>Hello from the CPU</code> <strong>之前</strong>，另一次是在 <code>Hello from the CPU</code> <strong>之后</strong>。</p><p>重构后main函数如下</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">helloGPU&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">cudaDeviceSynchronize();<span class="comment">//等待第一个Hello from the GPU</span></span><br><span class="line">helloCPU();<span class="comment">//打印Hello from the CPU</span></span><br><span class="line">helloGPU&lt;&lt;&lt;<span class="number">1</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">cudaDeviceSynchronize();<span class="comment">//等待第二个Hello from the GPU</span></span><br></pre></td></tr></table></figure><h3 id="编译并运行加速后的CUDA代码">编译并运行加速后的CUDA代码</h3><p>CUDA 平台附带 <a href="http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html"><strong>NVIDIA CUDA 编译器</strong></a> <code>nvcc</code>，可以编译 CUDA 加速应用程序，其中包含主机和设备代码。</p><p>曾使用过 <code>gcc</code> 的用户会对 <code>nvcc</code> 感到非常熟悉。例如，编译 <code>some-CUDA.cu</code> 文件就很简单：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvcc -arch=sm_70 -o out some-CUDA.cu -run</span><br></pre></td></tr></table></figure><ul><li><code>nvcc</code> 是使用 <code>nvcc</code> 编译器的命令行命令。</li><li>将 <code>some-CUDA.cu</code> 作为文件传递以进行编译。</li><li><code>o</code> 标志用于指定编译程序的输出文件。</li><li><code>arch</code> 标志表示该文件必须编译为哪个<strong>架构</strong>类型。本示例中，<code>sm_70</code> 将用于专门针对本实验运行的 Volta GPU 进行编译，但有意深究的用户可以参阅有关 <a href="http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#options-for-steering-gpu-code-generation"><code>arch</code> 标志</a>、<a href="http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list">虚拟架构特性</a> 和 <a href="http://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#gpu-feature-list">GPU特性</a> 的文档。</li><li>为方便起见，提供 <code>run</code> 标志将执行已成功编译的二进制文件。</li></ul></li></ul><h2 id="启动并行运行的核函数">启动并行运行的核函数</h2><p>程序员可通过执行配置指定有关如何启动核函数以在多个 GPU <strong>线程</strong>中并行运行的详细信息。更准确地说，程序员可通过执行配置指定线程组（称为<strong>线程块</strong>或简称为<strong>块</strong>）数量以及其希望每个线程块所包含的线程数量。执行配置的语法如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;&lt;&lt;线程块数, 每个线程块的线程数&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><p><strong>启动核函数时，核函数代码由每个已配置的线程块中的每个线程执行</strong>。</p><p>因此，如果假设已定义一个名为 <code>someKernel</code> 的核函数，则下列情况为真：</p><ul><li><code>someKernel&lt;&lt;&lt;1, 1&gt;&gt;()</code> 配置为在具有单线程的单个线程块中运行后，将只运行一次。</li><li><code>someKernel&lt;&lt;&lt;1, 10&gt;&gt;()</code> 配置为在具有 10 线程的单个线程块中运行后，将运行 10 次。</li><li><code>someKernel&lt;&lt;&lt;10, 1&gt;&gt;()</code> 配置为在 10 个线程块（每个均具有单线程）中运行后，将运行 10 次。</li><li><code>someKernel&lt;&lt;&lt;10, 10&gt;&gt;()</code> 配置为在 10 个线程块（每个均具有 10 线程）中运行后，将运行 100 次。</li></ul><h2 id="线程和块的索引">线程和块的索引</h2><p>每个线程在其线程块内部均会被分配一个索引，从 <code>0</code> 开始。此外，每个线程块也会被分配一个索引，并从 <code>0</code> 开始。正如线程组成线程块，线程块又会组成<strong>网格</strong>，而网格是 CUDA 线程层次结构中级别最高的实体。简言之，CUDA 核函数在由一个或多个线程块组成的网格中执行，且每个线程块中均包含相同数量的一个或多个线程。</p><ul><li>gridDim.x：网格中的线程块数</li><li>blockIdx.x：网格中线程块的索引</li><li>blockDim.x：线程块中的线程数</li><li>threadIdx.x：块中线程的索引</li></ul><p>CUDA 核函数可以访问能够识别如下两种索引的特殊变量：正在执行核函数的线程（位于线程块内）索引和线程所在的线程块（位于网格内）索引。这两种变量分别为 <code>threadIdx.x</code> 和 <code>blockIdx.x</code>。</p><h2 id="加速for循环">加速for循环</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如要并行此循环，必须执行以下 2 个步骤：</p><ul><li>必须编写完成<strong>循环的单次迭代</strong>工作的核函数。</li><li>由于核函数与其他正在运行的核函数无关，因此执行配置必须使核函数执行正确的次数，例如循环迭代的次数。</li></ul><h3 id="练习：使用单个线程块加速for循环">练习：使用单个线程块加速for循环</h3><p><a href="http://dli-604a4aa51b37-24abdb.aws.labs.courses.nvidia.com/lab/edit/04-loops/01-single-block-loop.cu"><code>01-single-block-loop.cu</code></a> 内的 <code>loop</code> 函数运行着一个“for 循环”并将连续打印 <code>0</code> 至 <code>9</code> 之间的所有数字。将 <code>loop</code> 函数重构为 CUDA 核函数，使其在启动后并行执行 <code>N</code> 次迭代。重构成功后，应仍能打印 <code>0</code> 至 <code>9</code> 之间的所有数字。</p><p>原代码：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> <span class="type">void</span> <span class="title function_">loop</span><span class="params">(<span class="type">int</span> N)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span> ; i&lt;N ; i++)</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This is iteration number %d\n&quot;</span>,i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> N =<span class="number">10</span>;</span><br><span class="line">  loop(N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重构后：</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This is iteration number %d\n&quot;</span>,threadIdx.x);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  loop&lt;&lt;&lt;<span class="number">1</span>,<span class="number">10</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>注：每个线程块内，thread.x的输出顺序是有序的，而不同线程块间的输出是无序的。如下，输出是无序的。但是若改为 loop&lt;&lt;&lt;10,2&gt;&gt;&gt;();可以发现仅线程块输出结果间是无序的，同一线程块内线程输出结果是有序的。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;This is iteration number %d\n&quot;</span>,blockIdx.x);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  loop&lt;&lt;&lt;<span class="number">10</span>,<span class="number">1</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">&#125;</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p>*查阅了一些资料，询问了老师之后，得知严格意义上线程块和线程的输出顺序是无法控制的，“并行本身其实就不应该控制先后顺序的，如果需要控制的话，那就说明这个任务不适合做矢量化了，因为他是顺序依赖的”，这里的线程输出有序，猜测是因为显示系统进行了后处理。*所以在实际使用中需要考虑使用线程块加速的适用性。</p><h2 id="调整线程块的大小以实现更多的并行化">调整线程块的大小以实现更多的并行化</h2><p>线程块包含的线程具有数量限制：确切地说是 1024 个。为增加加速应用程序中的并行量，我们必须要能在多个线程块之间进行协调。</p><p>CUDA 核函数可以访问给出块中线程数的特殊变量：<code>blockDim.x</code>。通过将此变量与 <code>blockIdx.x</code> 和 <code>threadIdx.x</code> 变量结合使用，并借助惯用表达式 <code>threadIdx.x + blockIdx.x * blockDim.x</code> 在包含多个线程的多个线程块之间组织并行执行，并行性将得以提升。以下是详细示例。</p><p>执行配置 <code>&lt;&lt;&lt;10, 10&gt;&gt;&gt;</code> 将启动共计拥有 100 个线程的网格，这些线程均包含在由 10 个线程组成的 10 个线程块中。因此，我们希望每个线程（<code>0</code> 至 <code>99</code> 之间）都能计算该线程的某个唯一索引。</p><ul><li>如果线程块 <code>blockIdx.x</code> 等于 <code>0</code>，则 <code>blockIdx.x * blockDim.x</code> 为 <code>0</code>。向 <code>0</code> 添加可能的 <code>threadIdx.x</code> 值（<code>0</code> 至 <code>9</code>），之后便可在包含 100 个线程的网格内生成索引 <code>0</code> 至 <code>9</code>。</li><li>如果线程块 <code>blockIdx.x</code> 等于 <code>1</code>，则 <code>blockIdx.x * blockDim.x</code> 为 <code>10</code>。向 <code>10</code> 添加可能的 <code>threadIdx.x</code> 值（<code>0</code> 至 <code>9</code>），之后便可在包含 100 个线程的网格内生成索引 <code>10</code> 至 <code>19</code>。</li></ul><h2 id="分配将要在GPU和CPU上访问的内存">分配将要在GPU和CPU上访问的内存</h2><p>CUDA 的最新版本（版本 6 和更高版本）已能轻松分配可用于 CPU 主机和任意数量 GPU 设备的内存。尽管现今有许多适用于内存管理并可支持加速应用程序中最优性能的 <a href="http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations">中高级技术</a>，但我们现在要介绍的基础 CUDA 内存管理技术不但能够支持远超 CPU 应用程序的卓越性能，而且几乎不会产生任何开发人员成本。</p><p>如要分配和释放内存，并获取可在主机和设备代码中引用的指针，请使用 <code>cudaMallocManaged</code> 和 <code>cudaFree</code> 取代对 <code>malloc</code> 和 <code>free</code> 的调用，如下例所示：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 只有CPU</span></span><br><span class="line"><span class="type">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="type">size_t</span> size = N * <span class="built_in">sizeof</span>(<span class="type">int</span>);</span><br><span class="line"><span class="type">int</span> *a;</span><br><span class="line"></span><br><span class="line">a = (<span class="type">int</span> *)<span class="built_in">malloc</span>(size);</span><br><span class="line"><span class="built_in">free</span>(a);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 加速后</span></span><br><span class="line"><span class="type">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="type">size_t</span> size = N * <span class="built_in">sizeof</span>(<span class="type">int</span>);</span><br><span class="line"><span class="type">int</span> *a;</span><br><span class="line"><span class="comment">// a的地址作为第一个参数传递</span></span><br><span class="line"><span class="built_in">cudaMallocManaged</span>(&amp;a, size);</span><br><span class="line"><span class="built_in">cudaFree</span>(a);</span><br></pre></td></tr></table></figure><h2 id="网格大小与工作量不匹配">网格大小与工作量不匹配</h2><p>可能会出现这样的情况，执行配置所创建的线程数无法匹配为实现并行循环所需的线程数。</p><p>一个常见的例子与希望选择的最佳线程块大小有关。例如，鉴于 GPU 的硬件特性，所含线程的数量为 32 的倍数的线程块是最理想的选择，因其具备性能上的优势。假设我们要启动一些线程块且每个线程块中均包含 256 个线程（32 的倍数），并需运行 1000 个并行任务（此处使用极小的数量以便于说明），则任何数量的线程块均无法在网格中精确生成 1000 个总线程，因为没有任何整数值在乘以 32 后可以恰好等于 1000。</p><p>这个问题可以通过以下方式轻松地解决：</p><ul><li>编写执行配置，使其创建的线程数<strong>超过</strong>执行分配工作所需的线程数。</li><li>将一个值作为参数传递到核函数 (<code>N</code>) 中，该值表示要处理的数据集总大小或完成工作所需的总线程数。</li><li>计算网格内的线程索引后（使用 <code>threadIdx + blockIdx*blockDim</code>），请检查该索引是否超过 <code>N</code>，并且只在不超过的情况下执行与核函数相关的工作。</li></ul><p>以下是编写执行配置的惯用方法示例，适用于 <code>N</code> 和线程块中的线程数已知，但无法保证网格中的线程数和 <code>N</code> 之间完全匹配的情况。如此一来，便可确保网格中至少始终拥有 <code>N</code> 所需的线程数，且超出的线程数至多仅可相当于 1 个线程块的线程数量：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// N已知</span></span><br><span class="line"><span class="type">int</span> N = <span class="number">100000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 每个线程块均包含256个线程</span></span><br><span class="line"><span class="type">size_t</span> threads_per_block = <span class="number">256</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 确保网格中至少始终拥有 `N` 所需的线程数，且超出的线程数至多仅可相当于 1 个线程块的线程数量</span></span><br><span class="line"><span class="type">size_t</span> number_of_blocks = (N + threads_per_block - <span class="number">1</span>) / threads_per_block;</span><br><span class="line"></span><br><span class="line">some_kernel&lt;&lt;&lt;number_of_blocks, threads_per_block&gt;&gt;&gt;(N);</span><br></pre></td></tr></table></figure><p>由于上述执行配置致使网格中的线程数超过 <code>N</code>，因此需要注意 <code>some_kernel</code> 定义中的内容，以确保 <code>some_kernel</code> 在由其中一个 ”额外的” 线程执行时不会尝试访问超出范围的数据元素：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">__global__ <span class="title">some_kernel</span><span class="params">(<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (idx &lt; N) <span class="comment">// 检查线程索引是否超过N</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">//条件满足时执行</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="跨网格的循环">跨网格的循环</h2><p>或出于选择，为了要创建具有超高性能的执行配置，或出于需要，一个网格中的线程数量可能会小于数据集的大小。请思考一下包含 1000 个元素的数组和包含 250 个线程的网格（此处使用极小的规模以便于说明）。此网格中的每个线程将需使用 4 次。如要实现此操作，一种常用方法便是在核函数中使用<strong>跨网格循环</strong>。</p><p>在跨网格循环中，每个线程将在网格内使用 <code>threadIdx + blockIdx*blockDim</code> 计算自身唯一的索引，并对数组内该索引的元素执行相应运算，然后将网格中的线程数添加到索引并重复此操作，直至超出数组范围。例如，对于包含 500 个元素的数组和包含 250 个线程的网格，网格中索引为 20 的线程将执行如下操作：</p><ul><li>对包含 500 个元素的数组的元素 20 执行相应运算</li><li>将其索引增加 250，使网格的大小达到 270</li><li>对包含 500 个元素的数组的元素 270 执行相应运算</li><li>将其索引增加 250，使网格的大小达到 520</li><li>由于 520 现已超出数组范围，因此线程将停止工作</li></ul><p>CUDA 提供一个可给出网格中线程块数的特殊变量：<code>gridDim.x</code>。然后计算网格中的总线程数，即网格中的线程块数乘以每个线程块中的线程数：<code>gridDim.x * blockDim.x</code>。带着这样的想法来看看以下核函数中网格跨度循环的详细示例：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">__global <span class="type">void</span> <span class="title">kernel</span><span class="params">(<span class="type">int</span> *a, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> indexWithinTheGrid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> gridStride = gridDim.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = indexWithinTheGrid; i &lt; N; i += gridStride)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// do work on a[i];</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="错误处理">错误处理</h2><ol><li>与在任何应用程序中一样，加速 CUDA 代码中的错误处理同样至关重要。即便不是大多数，也有许多 CUDA 函数（例如，<a href="http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY">内存管理函数</a>）会返回类型为 <code>cudaError_t</code> 的值，该值可用于检查调用函数时是否发生错误。以下是对调用 <code>cudaMallocManaged</code> 函数执行错误处理的示例：</li></ol><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cudaError_t err;</span><br><span class="line">err = <span class="built_in">cudaMallocManaged</span>(&amp;a, N)                    <span class="comment">// Assume the existence of `a` and `N`.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)                           <span class="comment">// `cudaSuccess` is provided by CUDA.</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(err)); <span class="comment">// `cudaGetErrorString` is provided by CUDA.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li>启动定义为返回 <code>void</code> 的核函数后，将不会返回类型为 <code>cudaError_t</code> 的值。为检查启动核函数时是否发生错误（例如，如果启动配置错误），CUDA 提供 <code>cudaGetLastError</code> 函数，该函数会返回类型为 <code>cudaError_t</code> 的值。</li></ol><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This launch should cause an error, but the kernel itself</span></span><br><span class="line"><span class="comment"> * cannot return it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">someKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">-1</span>&gt;&gt;&gt;();  <span class="comment">// -1 is not a valid number of threads.</span></span><br><span class="line"></span><br><span class="line">cudaError_t err;</span><br><span class="line">err = <span class="built_in">cudaGetLastError</span>(); <span class="comment">// `cudaGetLastError` will return the error from above.</span></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(err));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>最后，为捕捉异步错误（例如，在异步核函数执行期间），请务必检查后续同步 CUDA 运行时 API 调用所返回的状态（例如 <code>cudaDeviceSynchronize</code>）；如果之前启动的其中一个核函数失败，则将返回错误。</li></ol><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">cudaError_t err;</span><br><span class="line">err = cudaDeviceSynchronize();                <span class="comment">// Assume the existence of `a` and `N`.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)                           <span class="comment">// `cudaSuccess` is provided by CUDA.</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, cudaGetErrorString(err)); <span class="comment">// `cudaGetErrorString` is provided by CUDA.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CUDA错误处理功能">CUDA错误处理功能</h3><p>创建一个包装 CUDA 函数调用的宏对于检查错误十分有用。以下是一个宏示例，您可以在余下练习中随时使用：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> cudaError_t <span class="title">checkCuda</span><span class="params">(cudaError_t result)</span><span class="comment">//inline 关键字提示编译器尝试将该函数内联，这可以提高性能。</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (result != cudaSuccess) &#123;<span class="comment">//这个条件检查CUDA操作的结果是否不等于 cudaSuccess。如果发生错误，则执行if块内的代码。</span></span><br><span class="line">    <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;CUDA Runtime Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(result));</span><br><span class="line">    <span class="built_in">assert</span>(result == cudaSuccess);<span class="comment">//使用 assert 宏检查结果是否等于 cudaSuccess。如果不等于，这会触发一个断言失败，如果启用了断言，程序将终止。</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">/*...*/</span></span><br><span class="line">  <span class="built_in">checkCuda</span>( <span class="built_in">cudaDeviceSynchronize</span>() )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2维和3维的网格和块">2维和3维的网格和块</h2><p>可以将网格和线程块定义为最多具有 3 个维度。使用多个维度定义网格和线程块绝不会对其性能造成任何影响，但这在处理具有多个维度的数据时可能非常有用，例如 2D 矩阵。如要定义二维或三维网格或线程块，可以使用 CUDA 的 <code>dim3</code> 类型，即如下所示：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">threads_per_block</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">number_of_blocks</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">someKernel&lt;&lt;&lt;number_of_blocks, threads_per_block&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure><p>鉴于以上示例，<code>someKernel</code> 内部的变量 <code>gridDim.x</code>、<code>gridDim.y</code>、<code>blockDim.x</code> 和 <code>blockDim.y</code> 均将等于 <code>16</code>。</p><p>此处介绍一个万能的索引计算式</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> tid = blockIdx.z * (gridDim.x * gridDim.y) * (blockDim.x * blockDim.y * blockDim.z)\ </span><br><span class="line">    <span class="comment">//块在z方向上的索引</span></span><br><span class="line">          + blockIdx.y * gridDim.x * (blockDim.x * blockDim.y * blockDim.z) \</span><br><span class="line">    <span class="comment">//块在y方向上的索引</span></span><br><span class="line">          + blockIdx.x * (blockDim.x * blockDim.y * blockDim.z) \                      </span><br><span class="line">    <span class="comment">//块在x方向上的索引</span></span><br><span class="line">        + threadIdx.z * (blockDim.x * blockDim.y) \                                 </span><br><span class="line">    <span class="comment">//线程在z方向上的索引</span></span><br><span class="line">          + threadIdx.y * blockDim.x \                                               </span><br><span class="line">    <span class="comment">//线程在y方向上的索引</span></span><br><span class="line">          + threadIdx.x;                                                            </span><br><span class="line">    <span class="comment">//线程在x方向上的索引</span></span><br></pre></td></tr></table></figure><h1><strong>使用 CUDA C/C++ 统一内存和 Nsight Systems (nsys) 管理加速应用程序内存</strong></h1><h2 id="学习目标">学习目标</h2><p>当您在本实验完成学习后，您将能够：</p><ul><li>使用 <strong>Nsight Systems命令行分析器</strong> (<strong>nsys</strong>) 分析被加速的应用程序的性能。</li><li>利用对<strong>流多处理器</strong>的理解优化执行配置。</li><li>理解<strong>统一内存</strong>在页错误和数据迁移方面的行为。</li><li>使用<strong>异步内存预取</strong>减少页错误和数据迁移以提高性能。</li><li>采用循环式的迭代开发加快应用程序的优化加速和部署。</li></ul><h2 id="使用nsys性能分析器帮助应用程序迭代地进行优化">使用nsys性能分析器帮助应用程序迭代地进行优化</h2><p>如要确保优化加速代码库的尝试真正取得成功，唯一方法便是分析应用程序以获取有关其性能的定量信息。<code>nsys</code> 是指 NVIDIA 的Nsight System命令行分析器。该分析器附带于CUDA工具包中，提供分析被加速的应用程序性能的强大功能。</p><p><code>nsys</code> 使用起来十分简单，最基本用法是向其传递使用 <code>nvcc</code> 编译的可执行文件的路径。随后 <code>nsys</code> 会继续执行应用程序，并在此之后打印应用程序 GPU 活动的摘要输出、CUDA API 调用以及<strong>统一内存</strong>活动的相关信息。我们稍后会在本实验中详细介绍这一主题。</p><p>在加速应用程序或优化已经加速的应用程序时，我们应该采用科学的迭代方法。作出更改后需分析应用程序、做好记录并记录任何重构可能会对性能造成何种影响。尽早且经常进行此类观察通常会让您轻松获得足够的性能提升，以助您发布加速应用程序。此外，经常分析应用程序将使您了解到对 CUDA 代码库作出的特定更改会对其实际性能造成何种影响：而当只在代码库中进行多种更改后再分析应用程序时，将很难得知这一点。</p><p><code>nsys profile</code>将生成一个<code>qdrep</code>报告文件，该文件可以以多种方式使用。 我们在这里使用<code>--stats = true</code>标志表示我们希望打印输出摘要统计信息。 输出的信息有很多，包括：</p><ul><li>配置文件配置详细信息</li><li>报告文件的生成详细信息</li><li><strong>CUDA API统计信息</strong></li><li><strong>CUDA核函数的统计信息</strong></li><li><strong>CUDA内存操作统计信息（时间和大小）</strong></li><li>操作系统内核调用接口的统计信息</li></ul><p>值得一提的是，默认情况下，<code>nsys profile</code>不会覆盖现有的报告文件。 这样做是为了防止在进行概要分析时意外丢失工作。 如果出于某种原因，您宁愿覆盖现有的报告文件，例如在快速迭代期间，可以向<code>nsys profile</code>提供<code>-f</code>标志以允许覆盖现有的报告文件。</p><p><strong>练习</strong></p><p>优化前<a href="http://dli-604a4aa51b37-ee1ab7.aws.labs.courses.nvidia.com/lab/edit/01-vector-add/01-vector-add.cu">01-vector-add.cu</a></p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Host function to initialize vector elements. This function</span></span><br><span class="line"><span class="comment"> * simply initializes each element to equal its index in the</span></span><br><span class="line"><span class="comment"> * vector.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initWith</span><span class="params">(<span class="type">float</span> num, <span class="type">float</span> *a, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    a[i] = num;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Device kernel stores into `result` the sum of each</span></span><br><span class="line"><span class="comment"> * same-indexed value of `a` and `b`.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addVectorsInto</span><span class="params">(<span class="type">float</span> *result, <span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = index; i &lt; N; i += stride)</span><br><span class="line">  &#123;</span><br><span class="line">    result[i] = a[i] + b[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Host function to confirm values in `vector`. This function</span></span><br><span class="line"><span class="comment"> * assumes all values are the same `target` value.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">checkElementsAre</span><span class="params">(<span class="type">float</span> target, <span class="type">float</span> *vector, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span>(vector[i] != target)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;FAIL: vector[%d] - %0.0f does not equal %0.0f\n&quot;</span>, i, vector[i], target);</span><br><span class="line">      <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Success! All values calculated correctly.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">24</span>;</span><br><span class="line">  <span class="type">size_t</span> size = N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">  <span class="type">float</span> *a;</span><br><span class="line">  <span class="type">float</span> *b;</span><br><span class="line">  <span class="type">float</span> *c;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;a, size);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;b, size);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;c, size);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">initWith</span>(<span class="number">3</span>, a, N);</span><br><span class="line">  <span class="built_in">initWith</span>(<span class="number">4</span>, b, N);</span><br><span class="line">  <span class="built_in">initWith</span>(<span class="number">0</span>, c, N);</span><br><span class="line"></span><br><span class="line">  <span class="type">size_t</span> threadsPerBlock;</span><br><span class="line">  <span class="type">size_t</span> numberOfBlocks;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * nsys should register performance changes when execution configuration</span></span><br><span class="line"><span class="comment">   * is updated.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  threadsPerBlock = <span class="number">1</span>;</span><br><span class="line">  numberOfBlocks = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">  cudaError_t addVectorsErr;</span><br><span class="line">  cudaError_t asyncErr;</span><br><span class="line"></span><br><span class="line">  addVectorsInto&lt;&lt;&lt;numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(c, a, b, N);</span><br><span class="line"></span><br><span class="line">  addVectorsErr = <span class="built_in">cudaGetLastError</span>();</span><br><span class="line">  <span class="keyword">if</span>(addVectorsErr != cudaSuccess) <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(addVectorsErr));</span><br><span class="line"></span><br><span class="line">  asyncErr = <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">if</span>(asyncErr != cudaSuccess) <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(asyncErr));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkElementsAre</span>(<span class="number">7</span>, c, N);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(a);</span><br><span class="line">  <span class="built_in">cudaFree</span>(b);</span><br><span class="line">  <span class="built_in">cudaFree</span>(c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>优化将77行的的threadsPerblock改为1024即可，分析可得核函数运行时间加快了一个量级，此外cudaDeviceSynchronize()运行时间也大幅缩短，易于理解。</p><h2 id="流多处理器（Streaming-Multiprocessors）及查询GPU的设备配置">流多处理器（Streaming Multiprocessors）及查询GPU的设备配置</h2><h3 id="流多处理器和Warps">流多处理器和Warps</h3><p>运行 CUDA 应用程序的 GPU 具有称为<strong>流多处理器</strong>（或 <strong>SM</strong>）的处理单元。在核函数执行期间，将线程块提供给 SM 以供其执行。为支持 GPU 执行尽可能多的并行操作，您通常可以<em>选择线程块数量数倍于指定 GPU 上 SM 数量的网格大小</em>来提升性能。（提高SM的利用率）</p><p>此外，SM 会在一个名为<strong>warp</strong>的线程块内创建、管理、调度和执行包含 32 个线程的线程组。值得注意的是，可以<em>分配数量数倍于 32 的线程数量</em>来提升性能。</p><h3 id="以编程方式查询GPU设备属性">以编程方式查询GPU设备属性</h3><p>由于 GPU 上的 SM 数量会因所用的特定 GPU 而异，因此为支持可移植性，您不得将 SM 数量硬编码到代码库中。相反，应该以编程方式获取此信息。</p><p>以下所示为在 CUDA C/C++ 中获取 C 结构的方法，该结构包含当前处于活动状态的 GPU 设备的多个属性，其中包括设备的 SM 数量：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> deviceId;</span><br><span class="line"><span class="built_in">cudaGetDevice</span>(&amp;deviceId);                  <span class="comment">// `deviceId`现在指向活动的GPU</span></span><br><span class="line"></span><br><span class="line">cudaDeviceProp props;</span><br><span class="line"><span class="built_in">cudaGetDeviceProperties</span>(&amp;props, deviceId); <span class="comment">// `props` 现在有很多有用的关于主用GPU设备的属性</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="查询设备信息">查询设备信息</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> deviceId;</span><br><span class="line">  <span class="built_in">cudaGetDevice</span>(&amp;deviceId);</span><br><span class="line"></span><br><span class="line">  cudaDeviceProp props;</span><br><span class="line">  <span class="built_in">cudaGetDeviceProperties</span>(&amp;props, deviceId);</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> computeCapabilityMajor = props.major;</span><br><span class="line">  <span class="type">int</span> computeCapabilityMinor = props.minor;</span><br><span class="line">  <span class="type">int</span> multiProcessorCount = props.multiProcessorCount;</span><br><span class="line">  <span class="type">int</span> warpSize = props.warpSize;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Device ID: %d\nNumber of SMs: %d\nCompute Capability Major: %d\nCompute Capability Minor: %d\nWarp Size: %d\n&quot;</span>, deviceId, multiProcessorCount, computeCapabilityMajor, computeCapabilityMinor, warpSize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果样式下图</p><p><img src="https://cdn.jsdelivr.net/gh/forrest-wcb/markdown_img@main/img/202312292237862.png" alt="image-20231220165103264"></p><ul><li><strong>Compute Capability Major（计算能力主版本）：</strong> 这是主要版本号，表示GPU架构的主要特性。较新的主要版本通常支持更多的功能和性能提升。例如，Compute Capability Major 7 表示该GPU属于较新的架构。</li><li><strong>Compute Capability Minor（计算能力次版本）：</strong> 这是次要版本号，表示GPU架构的次要特性。通常，次要版本的提升表示一些较小的改进或优化。Compute Capability Minor 5 表示该GPU的次要版本。</li></ul><h3 id="将网格数调整为SM数，进一步优化矢量加法">将网格数调整为SM数，进一步优化矢量加法</h3><p>得知设备信息后，对执行配置进行调整，对01-vector-add.cu进一步优化。</p><p>线程块调整为80，线程数调成为640，重复多次运行分析，核函数运行时间约在0.12s左右，相比优化前的2.35s，以及上文的优化结果0.145s，有了不小的进步。</p><h2 id="获得统一内存的细节">获得统一内存的细节</h2><h3 id="统一内存-UM-的迁移">统一内存(UM)的迁移</h3><p>分配 UM 时，内存尚未驻留在主机或设备上。主机或设备尝试访问内存时会发生 <a href="https://en.wikipedia.org/wiki/Page_fault">页错误</a>，此时主机或设备会批量迁移所需的数据。同理，当 CPU 或加速系统中的任何 GPU 尝试访问尚未驻留在其上的内存时，会发生页错误并触发迁移。</p><p>能够执行页错误并按需迁移内存对于在加速应用程序中简化开发流程大有助益。此外，在处理展示稀疏访问模式的数据时（例如，在应用程序实际运行之前无法得知需要处理的数据时），以及在具有多个 GPU 的加速系统中，数据可能由多个 GPU 设备访问时，按需迁移内存将会带来显著优势。</p><p>有些情况下（例如，在运行时之前需要得知数据，以及需要大量连续的内存块时），我们还能有效规避页错误和按需数据迁移所产生的开销。</p><p>本实验的后续内容将侧重于对按需迁移的理解，以及如何在分析器输出中识别按需迁移。这些知识可让您在享受按需迁移优势的同时，减少其产生的开销。</p><h3 id="练习：探索统一内存（UM）的页错误">练习：探索统一内存（UM）的页错误</h3><p><code>nsys profile</code> 会提供描述所分析应用程序 UM 行为的输出。在本练习中，您将对一个简单的应用程序做出一些修改，并会在每次更改后利用 <code>nsys profile</code> 的统一内存输出部分，探讨 UM 数据迁移的行为方式。</p><p><a href="http://dli-604a4aa51b37-46802e.aws.labs.courses.nvidia.com/lab/edit/06-unified-memory-page-faults/01-page-faults.cu"><code>01-page-faults.cu</code></a> 包含 <code>hostFunction</code> 和 <code>gpuKernel</code> 函数，我们可以通过这两个函数并使用数字 <code>1</code> 初始化 <code>2&lt;&lt;24</code> 个单元向量的元素。主机函数和 GPU 核函数目前均未使用。</p><p>对于以下 4 个问题中的每一问题，请根据您对 UM 行为的理解，首先假设应会发生何种页错误，然后使用代码库中所提供 2 个函数中的其中一个或同时使用这两个函数编辑 <a href="http://dli-604a4aa51b37-46802e.aws.labs.courses.nvidia.com/lab/edit/06-unified-memory-page-faults/01-page-faults.cu"><code>01-page-faults.cu</code></a>以创建场景，以便您测试假设。</p><p>为了检验您的假设，请使用下面的代码执行单元来编译和分析代码。 一定要记录从<code>nsys profile --stats = true</code>输出中获得的假设以及结果。 在<code>nsys profile --stats = true</code>的输出中，您应该查找以下内容：</p><ul><li>输出中是否有 <em>CUDA内存操作统计信息</em> 部分？</li><li>如果是，这是否表示数据从主机到设备（HtoD）或从设备到主机（DtoH）的迁移？</li><li>进行迁移时，输出如何说明有多少个“操作”？ 如果看到许多小的内存迁移操作，则表明按需出现页面错误，并且每次在请求的位置出现页面错误时都会发生小内存迁移。</li></ul><p>以下是供您探索的方案，以及遇到困难时的解决方案：</p><ul><li>当仅通过CPU访问统一内存时，是否存在内存迁移和/或页面错误的证据？</li><li>当仅通过GPU访问统一内存时，是否有证据表明内存迁移和/或页面错误？</li><li>当先由CPU然后由GPU访问统一内存时，是否有证据表明存在内存迁移和/或页面错误？</li><li>当先由GPU然后由CPU访问统一内存时，是否存在内存迁移和/或页面错误的证据？</li></ul><p><img src="https://cdn.jsdelivr.net/gh/forrest-wcb/markdown_img@main/img/202312292238197.png" alt="image-20231223181124188"></p><p>上图为<code>nsys profile --stats = true</code>输出内容中显示的数据从设备到主机的迁移DtoH，总操作数为768，可以看到有许多小内存的迁移操作，验证了按需出现页面错误，并且每次在请求的位置出现页面错误时都会发生小内存迁移。</p><p>当 <code>nsys profile</code> 给出核函数所需的执行时间时，则在此函数执行期间发生的主机到设备页错误和数据迁移都会包含在所显示的执行时间中。故可以通过减少UM页错误和数据迁移的发生缩短核函数运行时间。</p><h2 id="异步内存预取">异步内存预取</h2><p>在主机到设备和设备到主机的内存传输过程中，我们使用一种技术来减少页错误和按需内存迁移成本，此强大技术称为<strong>异步内存预取</strong>。通过此技术，程序员可以在应用程序代码使用统一内存 (UM) 之前，在后台将其异步迁移至系统中的任何 CPU 或 GPU 设备。此举可以减少页错误和按需数据迁移所带来的成本，并进而提高 GPU 核函数和 CPU 函数的性能。</p><p>此外，预取往往会以更大的数据块来迁移数据，因此其迁移次数要低于按需迁移。此技术非常适用于以下情况：在运行时之前已知数据访问需求且数据访问并未采用稀疏模式。</p><p>CUDA 可通过 <code>cudaMemPrefetchAsync</code> 函数，轻松将托管内存异步预取到 GPU 设备或 CPU。以下所示为如何使用该函数将数据预取到当前处于活动状态的 GPU 设备，然后再预取到 CPU：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> deviceId;</span><br><span class="line"><span class="built_in">cudaGetDevice</span>(&amp;deviceId);                                  <span class="comment">// The ID of the currently active GPU device.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaMemPrefetchAsync</span>(pointerToSomeUMData, size, deviceId);<span class="comment">// 预取pointerToSomeUMData处size大小的数据至活动的GPU设备</span></span><br><span class="line"><span class="built_in">cudaMemPrefetchAsync</span>(pointerToSomeUMData, size, cudaCpuDeviceId); <span class="comment">// 预取回主机.`cudaCpuDeviceId`是可以直接使用的变量</span></span><br></pre></td></tr></table></figure><h3 id="练习：异步内存预取">练习：异步内存预取</h3><p>在 01-vector-add.cu应用程序中使用 <code>cudaMemPrefetchAsync</code> 函数开展 实验，以探究其会对页错误和内存迁移产生何种影响。</p><p>结果：可以看到内存传输次数减少了，但是每次传输的量增加了，并且内核执行时间大大减少了。</p><h1><strong>异步流及 CUDA C/C++ 应用程序的可视化性能分析</strong></h1><p>CUDA工具包附带了 <strong>Nsight Systems</strong>，这是一个功能强大的GUI应用程序，可支持CUDA应用程序的开发。 Nsight Systems为被加速的应用程序生成图形化的活动时间表，其中包含有关CUDA API调用、内核执行、内存活动以及<strong>CUDA流</strong>的使用的详细信息。</p><h2 id="学习目标-2">学习目标</h2><p>在完成本练习后，您将能够：</p><ul><li>使用<strong>Nsight Systems</strong>直观地描述由GPU加速的CUDA应用程序的时间表。</li><li>使用<strong>Nsight Systems</strong>识别和利用CUDA应用程序中的优化机会。</li><li>利用CUDA流在被加速的应用程序中并发执行核函数。</li><li>（ <strong>可选的进阶内容</strong> ）使用手动的设备内存分配，包括分配固定的内存，以便在并发CUDA流之间异步传输数据。</li></ul><h2 id="运行Nsight-Systems">运行Nsight Systems</h2><p>此处使用的是英伟达配置好的远程桌面，可以直接启动和使用Nsight Systems（但是无比的卡顿），建议在本地配置，进行可视化分析。</p><p>主要对前面的各种优化进行可视化分析，故不做记录</p><h2 id="并发CUDA流">并发CUDA流</h2><p>在 CUDA 编程中，<strong>流</strong>是由按顺序执行的一系列命令构成。在 CUDA 应用程序中，核函数的执行以及一些内存传输均在 CUDA 流中进行。不过直至此时，您仍未直接与 CUDA 流打交道；但实际上您的 CUDA 代码已在名为<em>默认流</em>的流中执行了其核函数。</p><p>除默认流以外，CUDA 程序员还可创建并使用非默认 CUDA 流，此举可支持执行多个操作，例如在不同的流中并发执行多个核函数。多流的使用可以为您的加速应用程序带来另外一个层次的并行，并能提供更多应用程序的优化机会。</p><p>以下为默认流和非默认流的关系</p><ul><li>给定流中的所有操作会按序执行。</li></ul><img src="https://cdn.jsdelivr.net/gh/forrest-wcb/markdown_img@main/img/202312291746109.png" alt="image-20231229174627015" style="zoom:50%;" /><ul><li>就不同非默认流中的操作而言，无法保证其会按彼此之间的任何特定顺序执行。</li></ul><img src="https://cdn.jsdelivr.net/gh/forrest-wcb/markdown_img@main/img/202312291747578.png" alt="image-20231229174728331" style="zoom:50%;" /><ul><li>默认流具有阻断能力，即，它会等待其它已在运行的所有流完成当前操作之后才运行，但在其自身运行完毕之前亦会阻碍其它流的运行</li></ul><img src="https://cdn.jsdelivr.net/gh/forrest-wcb/markdown_img@main/img/202312291748572.png" alt="image-20231229174809215" style="zoom:50%;" /><h3 id="创建，使用和销毁非默认CUDA流">创建，使用和销毁非默认CUDA流</h3><p>以下代码段演示了如何创建，利用和销毁非默认CUDA流。您会注意到，要在非默认CUDA流中启动CUDA核函数，必须将流作为执行配置的第4个可选参数传递给该核函数。到目前为止，您仅利用了执行配置的前两个参数：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cudaStream_t stream;   <span class="comment">// CUDA流的类型为 `cudaStream_t`</span></span><br><span class="line"><span class="built_in">cudaStreamCreate</span>(&amp;stream); <span class="comment">// 注意，必须将一个指针传递给 `cudaCreateStream`</span></span><br><span class="line"></span><br><span class="line">someKernel&lt;&lt;&lt;number_of_blocks, threads_per_block, <span class="number">0</span>, stream&gt;&gt;&gt;();   <span class="comment">// `stream` 作为第4个EC参数传递</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cudaStreamDestroy</span>(stream); <span class="comment">// 注意，将值（而不是指针）传递给 `cudaDestroyStream`</span></span><br></pre></td></tr></table></figure><p>但值得一提的是，执行配置的第3个可选参数超出了本实验的范围。此参数允许程序员提供<strong>共享内存</strong>中为每个内核启动动态分配的字节数。每个块分配给共享内存的默认字节数为“0”，在本练习的其余部分中，您将传递“ 0”作为该值，以便展示我们感兴趣的第4个参数。</p><h3 id="练习-2">练习</h3><p>源程序</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">printNumber</span><span class="params">(<span class="type">int</span> number)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, number);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    printNumber&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;(i);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以预见核函数的5次启动都在默认流顺次执行，可以用Nsight Systems进行可视化分析。由于核函数的所有 5 次启动均在同一个流中发生，因此看到 5 个核函数顺次执行也就不足为奇。此外，也可以这么说，由于默认流具有阻断作用，所以核函数都会在完成本次启动之后才启动下一次，而事实也是如此。</p><p>重构</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">printNumber</span><span class="params">(<span class="type">int</span> number)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, number);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    cudaStream_t stream;</span><br><span class="line">    <span class="built_in">cudaStreamCreate</span>(&amp;stream);</span><br><span class="line">    printNumber&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, stream&gt;&gt;&gt;(i);</span><br><span class="line">    <span class="built_in">cudaStreamDestroy</span>(stream);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>原程序</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initWith</span><span class="params">(<span class="type">float</span> num, <span class="type">float</span> *a, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = index; i &lt; N; i += stride)</span><br><span class="line">  &#123;</span><br><span class="line">    a[i] = num;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addVectorsInto</span><span class="params">(<span class="type">float</span> *result, <span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = index; i &lt; N; i += stride)</span><br><span class="line">  &#123;</span><br><span class="line">    result[i] = a[i] + b[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">checkElementsAre</span><span class="params">(<span class="type">float</span> target, <span class="type">float</span> *vector, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span>(vector[i] != target)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;FAIL: vector[%d] - %0.0f does not equal %0.0f\n&quot;</span>, i, vector[i], target);</span><br><span class="line">      <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Success! All values calculated correctly.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> deviceId;</span><br><span class="line">  <span class="type">int</span> numberOfSMs;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaGetDevice</span>(&amp;deviceId);</span><br><span class="line">  <span class="built_in">cudaDeviceGetAttribute</span>(&amp;numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">24</span>;</span><br><span class="line">  <span class="type">size_t</span> size = N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">  <span class="type">float</span> *a;</span><br><span class="line">  <span class="type">float</span> *b;</span><br><span class="line">  <span class="type">float</span> *c;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;a, size);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;b, size);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;c, size);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(a, size, deviceId);</span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(b, size, deviceId);</span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(c, size, deviceId);</span><br><span class="line"></span><br><span class="line">  <span class="type">size_t</span> threadsPerBlock;</span><br><span class="line">  <span class="type">size_t</span> numberOfBlocks;</span><br><span class="line"></span><br><span class="line">  threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">  numberOfBlocks = <span class="number">32</span> * numberOfSMs;</span><br><span class="line"></span><br><span class="line">  cudaError_t addVectorsErr;</span><br><span class="line">  cudaError_t asyncErr;</span><br><span class="line"></span><br><span class="line">  initWith&lt;&lt;&lt;numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(<span class="number">3</span>, a, N);</span><br><span class="line">  initWith&lt;&lt;&lt;numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(<span class="number">4</span>, b, N);</span><br><span class="line">  initWith&lt;&lt;&lt;numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(<span class="number">0</span>, c, N);</span><br><span class="line"></span><br><span class="line">  addVectorsInto&lt;&lt;&lt;numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(c, a, b, N);</span><br><span class="line"></span><br><span class="line">  addVectorsErr = <span class="built_in">cudaGetLastError</span>();</span><br><span class="line">  <span class="keyword">if</span>(addVectorsErr != cudaSuccess) <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(addVectorsErr));</span><br><span class="line"></span><br><span class="line">  asyncErr = <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">if</span>(asyncErr != cudaSuccess) <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(asyncErr));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(c, size, cudaCpuDeviceId);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkElementsAre</span>(<span class="number">7</span>, c, N);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(a);</span><br><span class="line">  <span class="built_in">cudaFree</span>(b);</span><br><span class="line">  <span class="built_in">cudaFree</span>(c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>重构</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initWith</span><span class="params">(<span class="type">float</span> num, <span class="type">float</span> *a, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = index; i &lt; N; i += stride)</span><br><span class="line">  &#123;</span><br><span class="line">    a[i] = num;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">addVectorsInto</span><span class="params">(<span class="type">float</span> *result, <span class="type">float</span> *a, <span class="type">float</span> *b, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = index; i &lt; N; i += stride)</span><br><span class="line">  &#123;</span><br><span class="line">    result[i] = a[i] + b[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">checkElementsAre</span><span class="params">(<span class="type">float</span> target, <span class="type">float</span> *vector, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span>(vector[i] != target)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">&quot;FAIL: vector[%d] - %0.0f does not equal %0.0f\n&quot;</span>, i, vector[i], target);</span><br><span class="line">      <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Success! All values calculated correctly.\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="type">int</span> deviceId;</span><br><span class="line">  <span class="type">int</span> numberOfSMs;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaGetDevice</span>(&amp;deviceId);</span><br><span class="line">  <span class="built_in">cudaDeviceGetAttribute</span>(&amp;numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">24</span>;</span><br><span class="line">  <span class="type">size_t</span> size = N * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">  <span class="type">float</span> *a;</span><br><span class="line">  <span class="type">float</span> *b;</span><br><span class="line">  <span class="type">float</span> *c;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;a, size);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;b, size);</span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;c, size);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(a, size, deviceId);</span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(b, size, deviceId);</span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(c, size, deviceId);</span><br><span class="line"></span><br><span class="line">  <span class="type">size_t</span> threadsPerBlock;</span><br><span class="line">  <span class="type">size_t</span> numberOfBlocks;</span><br><span class="line"></span><br><span class="line">  threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">  numberOfBlocks = <span class="number">32</span> * numberOfSMs;</span><br><span class="line"></span><br><span class="line">  cudaError_t addVectorsErr;</span><br><span class="line">  cudaError_t asyncErr;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Create 3 streams to run initialize the 3 data vectors in parallel.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  cudaStream_t stream1, stream2, stream3;</span><br><span class="line">  <span class="built_in">cudaStreamCreate</span>(&amp;stream1);</span><br><span class="line">  <span class="built_in">cudaStreamCreate</span>(&amp;stream2);</span><br><span class="line">  <span class="built_in">cudaStreamCreate</span>(&amp;stream3);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Give each `initWith` launch its own non-standard stream.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  initWith&lt;&lt;&lt;numberOfBlocks, threadsPerBlock, <span class="number">0</span>, stream1&gt;&gt;&gt;(<span class="number">3</span>, a, N);</span><br><span class="line">  initWith&lt;&lt;&lt;numberOfBlocks, threadsPerBlock, <span class="number">0</span>, stream2&gt;&gt;&gt;(<span class="number">4</span>, b, N);</span><br><span class="line">  initWith&lt;&lt;&lt;numberOfBlocks, threadsPerBlock, <span class="number">0</span>, stream3&gt;&gt;&gt;(<span class="number">0</span>, c, N);</span><br><span class="line"></span><br><span class="line">  addVectorsInto&lt;&lt;&lt;numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(c, a, b, N);</span><br><span class="line"></span><br><span class="line">  addVectorsErr = <span class="built_in">cudaGetLastError</span>();</span><br><span class="line">  <span class="keyword">if</span>(addVectorsErr != cudaSuccess) <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(addVectorsErr));</span><br><span class="line"></span><br><span class="line">  asyncErr = <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">  <span class="keyword">if</span>(asyncErr != cudaSuccess) <span class="built_in">printf</span>(<span class="string">&quot;Error: %s\n&quot;</span>, <span class="built_in">cudaGetErrorString</span>(asyncErr));</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaMemPrefetchAsync</span>(c, size, cudaCpuDeviceId);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">checkElementsAre</span>(<span class="number">7</span>, c, N);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Destroy streams when they are no longer needed.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaStreamDestroy</span>(stream1);</span><br><span class="line">  <span class="built_in">cudaStreamDestroy</span>(stream2);</span><br><span class="line">  <span class="built_in">cudaStreamDestroy</span>(stream3);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(a);</span><br><span class="line">  <span class="built_in">cudaFree</span>(b);</span><br><span class="line">  <span class="built_in">cudaFree</span>(c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="最终任务：加速和优化N体模拟器">最终任务：加速和优化N体模拟器</h2><p><a href="https://en.wikipedia.org/wiki/N-body_problem">n-body</a> 模拟器可以预测通过引力相互作用的一组物体的个体运动。<a href="http://dli-604a4aa51b37-c4c714.aws.labs.courses.nvidia.com/lab/edit/09-nbody/01-nbody.cu">01-nbody.cu</a> 包含一个简单而有效的 n-body 模拟器，适合用于在三维空间移动的物体。我们可通过向该应用程序传递一个命令行参数以影响系统中的物体数量。</p><p>以目前的仅用CPU的情况下，此应用程序大约需要5秒钟才能运行4096个物体，需要<strong>20分钟</strong>才能运行65536个物体。您的任务是用GPU加速程序，同时保持仿真的正确性。</p><p>源程序如下：</p><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;timer.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;files.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SOFTENING 1e-9f</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Each body contains x, y, and z coordinate positions,</span></span><br><span class="line"><span class="comment"> * as well as velocities in the x, y, and z directions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123; <span class="type">float</span> x, y, z, vx, vy, vz; &#125; Body;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Calculate the gravitational impact of all bodies in the system</span></span><br><span class="line"><span class="comment"> * on all others.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bodyForce</span><span class="params">(Body *p, <span class="type">float</span> dt, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    <span class="type">float</span> Fx = <span class="number">0.0f</span>; <span class="type">float</span> Fy = <span class="number">0.0f</span>; <span class="type">float</span> Fz = <span class="number">0.0f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">      <span class="type">float</span> dx = p[j].x - p[i].x;</span><br><span class="line">      <span class="type">float</span> dy = p[j].y - p[i].y;</span><br><span class="line">      <span class="type">float</span> dz = p[j].z - p[i].z;</span><br><span class="line">      <span class="type">float</span> distSqr = dx*dx + dy*dy + dz*dz + SOFTENING;</span><br><span class="line">      <span class="type">float</span> invDist = <span class="built_in">rsqrtf</span>(distSqr);</span><br><span class="line">      <span class="type">float</span> invDist3 = invDist * invDist * invDist;</span><br><span class="line"></span><br><span class="line">      Fx += dx * invDist3; Fy += dy * invDist3; Fz += dz * invDist3;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    p[i].vx += dt*Fx; p[i].vy += dt*Fy; p[i].vz += dt*Fz;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">const</span> <span class="type">int</span> argc, <span class="type">const</span> <span class="type">char</span>** argv)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The assessment will test against both 2&lt;11 and 2&lt;15.</span></span><br><span class="line">  <span class="comment">// Feel free to pass the command line argument 15 when you gernate ./nbody report files</span></span><br><span class="line">  <span class="type">int</span> nBodies = <span class="number">2</span>&lt;&lt;<span class="number">11</span>;</span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">1</span>) nBodies = <span class="number">2</span>&lt;&lt;<span class="built_in">atoi</span>(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The assessment will pass hidden initialized values to check for correctness.</span></span><br><span class="line">  <span class="comment">// You should not make changes to these files, or else the assessment will not work.</span></span><br><span class="line">  <span class="type">const</span> <span class="type">char</span> * initialized_values;</span><br><span class="line">  <span class="type">const</span> <span class="type">char</span> * solution_values;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (nBodies == <span class="number">2</span>&lt;&lt;<span class="number">11</span>) &#123;</span><br><span class="line">    initialized_values = <span class="string">&quot;files/initialized_4096&quot;</span>;</span><br><span class="line">    solution_values = <span class="string">&quot;files/solution_4096&quot;</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">// nBodies == 2&lt;&lt;15</span></span><br><span class="line">    initialized_values = <span class="string">&quot;files/initialized_65536&quot;</span>;</span><br><span class="line">    solution_values = <span class="string">&quot;files/solution_65536&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">2</span>) initialized_values = argv[<span class="number">2</span>];</span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">3</span>) solution_values = argv[<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">float</span> dt = <span class="number">0.01f</span>; <span class="comment">// Time step</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> nIters = <span class="number">10</span>;  <span class="comment">// Simulation iterations</span></span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> bytes = nBodies * <span class="built_in">sizeof</span>(Body);</span><br><span class="line">  <span class="type">float</span> *buf;</span><br><span class="line"></span><br><span class="line">  buf = (<span class="type">float</span> *)<span class="built_in">malloc</span>(bytes);</span><br><span class="line"></span><br><span class="line">  Body *p = (Body*)buf;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">read_values_from_file</span>(initialized_values, buf, bytes);</span><br><span class="line"></span><br><span class="line">  <span class="type">double</span> totalTime = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * This simulation will run for 10 cycles of time, calculating gravitational</span></span><br><span class="line"><span class="comment">   * interaction amongst bodies, and adjusting their positions to reflect.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> iter = <span class="number">0</span>; iter &lt; nIters; iter++) &#123;</span><br><span class="line">    <span class="built_in">StartTimer</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * You will likely wish to refactor the work being done in `bodyForce`,</span></span><br><span class="line"><span class="comment">   * and potentially the work to integrate the positions.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">bodyForce</span>(p, dt, nBodies); <span class="comment">// compute interbody forces</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * This position integration cannot occur until this round of `bodyForce` has completed.</span></span><br><span class="line"><span class="comment">   * Also, the next round of `bodyForce` cannot begin until the integration is complete.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span> ; i &lt; nBodies; i++) &#123; <span class="comment">// integrate position</span></span><br><span class="line">      p[i].x += p[i].vx*dt;</span><br><span class="line">      p[i].y += p[i].vy*dt;</span><br><span class="line">      p[i].z += p[i].vz*dt;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">double</span> tElapsed = <span class="built_in">GetTimer</span>() / <span class="number">1000.0</span>;</span><br><span class="line">    totalTime += tElapsed;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">double</span> avgTime = totalTime / (<span class="type">double</span>)(nIters);</span><br><span class="line">  <span class="type">float</span> billionsOfOpsPerSecond = <span class="number">1e-9</span> * nBodies * nBodies / avgTime;</span><br><span class="line">  <span class="built_in">write_values_to_file</span>(solution_values, buf, bytes);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// You will likely enjoy watching this value grow as you accelerate the application,</span></span><br><span class="line">  <span class="comment">// but beware that a failure to correctly synchronize the device might result in</span></span><br><span class="line">  <span class="comment">// unrealistically high values.</span></span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%0.3f Billion Interactions / second&quot;</span>, billionsOfOpsPerSecond);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">free</span>(buf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>优化热点如下：</p><ol><li>将bodyforce函数改为核函数，外层循环可以优化，内层循环具有顺序依赖故不做改动</li><li>将bodyforce函数执行后的将引力集成到各物体位置的for循环改为核函数。“该集成不仅需在 <code>bodyForce</code> 函数运行后进行，并且需在下一次调用 <code>bodyForce</code> 函数之前完成。”所以，在执行前添加cudaDeviceSynchronize()语句</li><li>执行配置根据SMs和wraps数量进行配置（此处线程数越大，核函数运行时间反而变长，取32和64的运行时间相对较优）</li></ol><p>重构结果</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;timer.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;files.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SOFTENING 1e-9f</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123; <span class="type">float</span> x, y, z, vx, vy, vz; &#125; Body;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">bodyForce</span><span class="params">(Body *p, <span class="type">float</span> dt, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = index; i &lt; n; i += stride)&#123;</span><br><span class="line">    <span class="type">float</span> Fx = <span class="number">0.0f</span>; <span class="type">float</span> Fy = <span class="number">0.0f</span>; <span class="type">float</span> Fz = <span class="number">0.0f</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">      <span class="type">float</span> dx = p[j].x - p[i].x;</span><br><span class="line">      <span class="type">float</span> dy = p[j].y - p[i].y;</span><br><span class="line">      <span class="type">float</span> dz = p[j].z - p[i].z;</span><br><span class="line">      <span class="type">float</span> distSqr = dx*dx + dy*dy + dz*dz + SOFTENING;</span><br><span class="line">      <span class="type">float</span> invDist = <span class="built_in">rsqrtf</span>(distSqr);</span><br><span class="line">      <span class="type">float</span> invDist3 = invDist * invDist * invDist;</span><br><span class="line"></span><br><span class="line">      Fx += dx * invDist3; Fy += dy * invDist3; Fz += dz * invDist3;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    p[i].vx += dt*Fx; p[i].vy += dt*Fy; p[i].vz += dt*Fz;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">integrate_position</span><span class="params">(Body *p,<span class="type">float</span> dt,<span class="type">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="type">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">       <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> (<span class="type">int</span> i = index; i &lt; n; i += stride) &#123;</span><br><span class="line">                <span class="comment">// integrate position</span></span><br><span class="line">                p[i].x += p[i].vx*dt;</span><br><span class="line">                p[i].y += p[i].vy*dt;</span><br><span class="line">                p[i].z += p[i].vz*dt;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">const</span> <span class="type">int</span> argc, <span class="type">const</span> <span class="type">char</span>** argv)</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> deviceId;</span><br><span class="line">  <span class="type">int</span> numberOfSMs;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaGetDevice</span>(&amp;deviceId);</span><br><span class="line">  <span class="built_in">cudaDeviceGetAttribute</span>(&amp;numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> nBodies = <span class="number">2</span>&lt;&lt;<span class="number">11</span>;</span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">1</span>) nBodies = <span class="number">2</span>&lt;&lt;<span class="built_in">atoi</span>(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">char</span> * initialized_values;</span><br><span class="line">  <span class="type">const</span> <span class="type">char</span> * solution_values;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (nBodies == <span class="number">2</span>&lt;&lt;<span class="number">11</span>) &#123;</span><br><span class="line">    initialized_values = <span class="string">&quot;files/initialized_4096&quot;</span>;</span><br><span class="line">    solution_values = <span class="string">&quot;files/solution_4096&quot;</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">// nBodies == 2&lt;&lt;15</span></span><br><span class="line">    initialized_values = <span class="string">&quot;files/initialized_65536&quot;</span>;</span><br><span class="line">    solution_values = <span class="string">&quot;files/solution_65536&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">2</span>) initialized_values = argv[<span class="number">2</span>];</span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">3</span>) solution_values = argv[<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">float</span> dt = <span class="number">0.01f</span>; <span class="comment">// Time step</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> nIters = <span class="number">10</span>;  <span class="comment">// Simulation iterations</span></span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> bytes = nBodies * <span class="built_in">sizeof</span>(Body);</span><br><span class="line">  <span class="type">float</span> *buf;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//buf = (float *)malloc(bytes);</span></span><br><span class="line">  <span class="built_in">cudaMallocManaged</span>(&amp;buf, bytes);</span><br><span class="line">  </span><br><span class="line">  Body *p = (Body*)buf;</span><br><span class="line">  <span class="comment">//cudaMemPrefetchAsync(p, bytes, deviceId);</span></span><br><span class="line">  <span class="type">size_t</span> threadsPerBlock = <span class="number">64</span>;</span><br><span class="line">  <span class="type">size_t</span> numberOfBlocks = <span class="number">32</span> * numberOfSMs;</span><br><span class="line">  </span><br><span class="line">  <span class="built_in">read_values_from_file</span>(initialized_values, buf, bytes);</span><br><span class="line"></span><br><span class="line">  <span class="type">double</span> totalTime = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> iter = <span class="number">0</span>; iter &lt; nIters; iter++) &#123;</span><br><span class="line">    <span class="built_in">StartTimer</span>();</span><br><span class="line">    <span class="comment">//cudaStream_t stream;   // CUDA流的类型为 `cudaStream_t`</span></span><br><span class="line">    <span class="comment">//cudaStreamCreate(&amp;stream); </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    bodyForce&lt;&lt;&lt; numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(p, dt, nBodies); <span class="comment">// compute interbody forces</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    integrate_position&lt;&lt;&lt; numberOfBlocks, threadsPerBlock&gt;&gt;&gt;(p, dt, nBodies);</span><br><span class="line">    <span class="comment">//cudaDeviceSynchronize();</span></span><br><span class="line">    <span class="comment">//cudaStreamDestroy(stream); </span></span><br><span class="line">    </span><br><span class="line">    <span class="type">const</span> <span class="type">double</span> tElapsed = <span class="built_in">GetTimer</span>() / <span class="number">1000.0</span>;</span><br><span class="line">    totalTime += tElapsed;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//cudaDeviceSynchronize();</span></span><br><span class="line">  <span class="type">double</span> avgTime = totalTime / (<span class="type">double</span>)(nIters);</span><br><span class="line">  <span class="type">float</span> billionsOfOpsPerSecond = <span class="number">1e-9</span> * nBodies * nBodies / avgTime;</span><br><span class="line">  <span class="built_in">write_values_to_file</span>(solution_values, buf, bytes);</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;%0.3f Billion Interactions / second&quot;</span>, billionsOfOpsPerSecond);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">cudaFree</span>(buf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最后优化结果，计算4096个物体</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">您的应用程序运行了: 0.1543秒</span><br><span class="line">您的应用程序运行速度是  22.358 Billion Interactions / second</span><br></pre></td></tr></table></figure><p>计算65536个物体</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">您的应用程序运行了: 0.4912秒</span><br><span class="line">您的应用程序运行速度是  121.163 Billion Interactions / second</span><br></pre></td></tr></table></figure><p>建议结合可视化分析，也许可以得到更优的结果。（本人由于懒得部署本地Nsight Systems，且英伟达提供的远程桌面过于卡顿，故没有结合可视化分析。虽然尝试了异步内存预取和使用非默认流，但是效果并不显著，因为没法进行可视化分析，我也不清楚内存转移时间是否缩短和不同非默认流是否并行，所以使用可视化分析，可能可以进行进一步的优化）</p><h2 id="小结">小结</h2><p>姑且算是接触了cuda c编程的皮毛。缘由是上学期心头一热选的公选课，但由于要跨校区上课，所以也没去过几节课（别问，就是懒）。没退课的原因就是感觉cuda加速在以后可能会发挥作用，而且这是学校帮忙兑换的Nvidia线上自主培训课程，价值89刀，薅羊毛谁不喜欢。</p><p>平时没学，为了完成大作业，就在这几周速通了，学习记录在这篇blog。此外由于运行都是在英伟达提供的远程云环境中，少了配置cuda环境的许多麻烦。上周完成大作业的时候，跌跌撞撞地配了快一天的环境😅，如果后面有想法，打算再写篇博客记录下环境配置。</p><hr><p>——2023年倒数第三天的晚上。</p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cuda加速计算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拾珠</title>
      <link href="/2023/09/14/poems/"/>
      <url>/2023/09/14/poems/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Oh, this is an invalid password. Check and try again, please." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="5dcbb3a2f08758a6cc943b9e8e9134e2beaa7f9c07ec3041df975c7939b8332d">9b6b9f34db6f4b29eb6e28ae1e5cb9733524fb577de97028c44cd9a236e1257970340784def89129ea8be0ae99cc3d40bfd993db5ff383ef2612eead5c0f4002b4a9b49d8c7b18e9f530a07d679fd8e5599055bc705811622d47618b7c50ea58b930ff37031db196ac42615b9d6f991fa898a83d9a6654298954011861bc7f3f7eb9eb0586eb1b36bc9fb85cc0d8bde84d2b0de9946491fa60caef900472223fbdb56dda1503b4275b6805064a994ccd3be5a144f3d27a096bde86741250a0e4b4c7c14f921ecb5e314a1c713e1451f9b9902e3ed8dd42333a7dd082d338a4bb74058f7b81495678099ed483a1a3170c79a99a9a8375ea9b6b158266c75ff0e73573211a154113cf606f521f73da3b4fbc4267d7a40581bff26b2e85690aa602b05ec720b40f492cc6da72d5588ef35c2609067a8a287f1138b9da887d8fbca8c2d6e15118886e969d1f46d87c9597f565be7a12170b16bac025aaeac2f17d5ae8afa4cc9411c01cc1a6ea715dc7088b622f4c8a3c140cbaf60a5a7ce4a8ee997ebaad179c19d48d37cf92a51b9b51d112488b20c196e941d0f7bc9011c2074111c6daae6165d5d3c6c866148684ef4a4f35d3eb6a4011f2f766bf746c88d12eded586cb978902e8f12edc84382ae5ff4c86d1744abf14d42d682b7bed3b182f1d8707caccdcb0e96f372a93d5ada82c3a24abaa343301b356883ecc6945ac6f24d82617b2ce25894edd61ba2df655351c0eae75e21ea08988dd5a6f2743025bc7207094702044cd099e06121a0c61dda40a75a1a99ccead4df1ca07876afd443646b60010bc28b6ede8aea087a46e462025cac15278f808c686c46525c2a769315e6a54fd03e223754572e8bc9fcfd1c445aa1e7b1675528bebebd614a8cc3603f5d182a12c98abe1963dbfe76194e86a1044a2ffcf8a413b450ca66f0558aed48e26e7b226c5ed64605192c8f822df52144a66b5b6812620299abe41b96f7817c4bd9603550764c10c104e92687c08aabc4a1a39fbb7e467170986416265341fb619cc6ad63ce56d0e2c47fa2b715f0750d69794db80c81f29a13c1bf2ca0feef2a0997abe5a4f45b49aff9d362722882eb33c30500706a25657fde27e91d691560d60200447b86ad46091456897da0351d9a3a2eceadcefc4178d789cdaa2f56ceda56698006e2436680b866720e3b24d0b432aa8c4e0790c53d25bd0d4d691b5aa968efd79da395c04af400f542a6a59a7565ea9d99361d547e88a49f0181a78714d9b8f0d5a3d76a70bf86d275d9e0da13e80ac8a0f79a19b1da2b58b4f72c3a89903596f6d410c4cbd5209854a205f7d527c02d1ab46f99805caa988203d6ce8b1a50805e62d5db93664f9b6a43e7e80f13053153ac3497ed24464e0759ec2149920d9c177f5ba3b91c92d338085684199b06cc9af398d9be60924de3a9b2413b69da647afc5bf05ea6e950e8257739f0a1fc988308c18b0b886ee804196e9f9be9e4b16d9b974b77f20efd4212c7d899b703f42594223484d07a73b0dac773502ec915de18964f145ba28ed706c70a4cc56e0fe51175a38fa19f4b635899ff8bf926aa38cb6299b3edc012b1e464b76105ea71a685fa8edc9bbc251fedc6de8b0e54c9d601162a445aceaabae757f65b77f5d61156494e75b38dfd5b5b374c269c95f898014f77e8501625b0e6d3a91d8e663111b29d2ebff431564e094fac3bd49d92f18277a59eab84b6d06486207de1416648de347cefc61e7b94e5026af47c18b69cda1508272b064419708b20d28743464ad815157c464929833a9bf710b955b1536d01ed3bcc939b047f661470cb0c9179c0d125003a56b9ee75d045abc47728f696eb47c296ebd15a9dc5f49acaf600c2f70a659ec2688a262db4b868a8080c4110bc4885db3892459d4a39b3708a0c5555c853d2864781ee62d13c5444065123f360e61d1c067045f68aee47aa0ae9eea7a332603b1b2aababc5f2c8aa55de19750a7e8f2c96caef40ad0ced748360c05dcbe55b5c34368899714e370b643c7decb41d1e1ef036086aabf9cd78ae4f6f05c9f4d22632b4152d0482d5eeedef5f7c4d9b04b9e24080005600987e2b5d3c50b0f97bf81055d48df0e7990a4c189473bfd770e2b60cdca6165cde62a5d0c9e13f15200b4b4eff270e774e103f0255258fc76a2ae9fe1326c365d6b25c3d63faeb18c6a8f3da094eb3042f788b26f3d7861d90071928480122a2821cb2fe7f215f44c530520218c7cdf842da7f02a8fde22f6683b82a19afc118e54cdd251db246f1eae742524e07ef951708c3be7c498836935bd9832738af65488cd311dc7ddc4ef39779171f6519d72f7a15aa21fb5112734e0f93d5d305b00c84d1a55439ee8c019dbeb3b1a371a2a811cb18812c93a7a8cebf8597561ac2d7f26fdf3ab6802e08502a5a0c073f7ad4f701beb303794216d62987ab12727e882db3ac07ee99fe7df1b92e7b38a0c82bd3c76edc0eafc65ca6864e681ac1e5b29532976ea74110ae44da3f92986a2e404419830322d85c8447e74492b22a3e705d2ba149150ece4a62a2864c8ce02419f9afd9253a681f4e29c2ecd3ae802682b3cfa0c2ea2e98eba8a5d2ec0c6469172706011fd4bbf7c226ecba45e12c31189aa6e1be2d668d18d587cb29784d32b08dc5c7bd4276b1d211e3f245ac875233d98458abeb0449a84686c3ef9b2d4b59f6802c3133e2430e995af4fe5cd1d24426840bdaf585f7c50d3cc15a9f33756beb8e39425b3a0a5bb939c5f3f1b248194e6bcf262271a62dc1a3c361ca3a4f6c019c430f7ebc8711b9a096e87080da9b069830a231a81cc6b7466fb6056f7e580f3b16b1b5a696e33599875a3827b34072cde7028be982020ff17bcdff0bf34d36cda59ca6bf3c9496a836eccca9eeb830ab3f5cc0d28322d2fccd0e09c3bcecd708ae6780ea4c1e9967f2e42c00f0ccdff7be646112e6cfc6c4f16fbe430a6933828e9ba65d60f7d5fea0dcc8442fc40f2a793bb51eedbfff3ea7ce60a0e6b28775e55f126f09bad086ca56405eee2557c58ba2b8bb671b369ac75532bd1fffc02d5e02ae8391bd4e4b378ebb3bdb011e6b848c969854d35f17b4c5f5bed93c81463aa1cac685c131c221ddeb162385ad407c21f33661f31b0c2b4caa1615c10f4326499c90e164ce468f97c96cbe6207b428ba608a02388de5e26750a6f82da8191ffdbbe86962aa2b558b0e947f07ba4763df14e344302ab8096f0c1940600716ce224d7457638dcbfaa4149bb5c7b00f6aee722b64c57f4f467f9244feb7fb5d9dee05e33f874356cb8202696930ee05c1199bcfb52b22d21a1187a8cbfeec0ee512683dfd38ba7ac2249259f52963ad00b5199cdc85f1e9dc0b59ff93e568046ddc7169726127c3b6e7c37b4c0eba43f8f1d7933d2494715e4530898703203038d970597c64faa44748d1ee003c52b79c9bf7527ead452056f05be82a0585e4da465df67a91aad7b1f6910e24bec98d8b9bdeef00ea0e5a691ed5df330846a4efde7ef61236aa6222d691ba31cf67aa337c64112774be1e62894bbe5f46dcaa429d58689e3e15de629ade1b97c33db911e97669276973ea9067de16ed35da0b51e9abca800b92aee2ab7af0e437f50b66eed75842113a91ba2037298ced0b497dafe049849eca62201c98c86a700d6d1dff9d796efba39242ffb710b3e63808d38192b9390624c4c98b5d6f5e4c3fff1c725473c4fca4dd72ce2b08586f2275fde3fcf7a618afe41b873b2edd4c5eee106069bc00140dc7bee0bcb4504073bc11a1bea073da56d32810a7174cff328caf3e03ae06b11783ba5da76021c69409efb97cce5966423e4e662a16ae083e3a6e9a1160293081510b62ca60eedacf8de3b89daf7ee94a676a897420370e8474a224e579d76ec01c56d8e341d6b9454d1a345d418cc998d5941c90ec4942f22800fd475071f2b0ba01697bf2b9ffc087100d22001653328687251672e81a9403501119c05b3f8260c584d622766112667ea0295316ea52766e9b59e6ea84e4e5c09d1e8fbd5c8dc4d95e531c3155d42256771368d9314a1d23a0dd8c0444794d38d3c5cbfec9f487859e13a12f0d5dfc3ffb643c5a08561e98bf67cbc355d0d80b6ad5e677f6d836801d996427630b83130f9ec694600d8235a9d0808fdd3291cff1238ce7a97f7bcb25f56b9638858afcf818f09a6b23da6419065cc4a5d3ea7836c9ffe9b440a4c896f12427328016a8a048188bdc1789c01f97c46caeb7f8fe2ac353b7ecd7764f77d7e5abc520e831572df7e665cef08349bd81b98485cbf7fbb1b4679340c1f51670299d9c5715151325a6bbc5c82ee182c27477283617612cf40a0df9e391dedf7a5e2078a9eb19b633b4554ba6ec6a8060d965f758cc13d15c378be50f39a17fefaa38b570c836f30272bc7f3e598aef1d5d1792e59dac19f543c6b07fc6c7c7be4534176bb46bf4f0c695f81abd462c01529e8f56ca6585749940f60cedfa2c664692fd272221cec9d06f4b22656e430ba4a1da5b39b5e872018570264008caa79c33f2066c9fdd551e541f8257377c68a4ddc5e69293bb3b547c9510ad0f0aa1def9f576d48a458238f3baffda19498785515a70fec06d6c9f79a7bb91d34ec01b6237182add78ac0467f03725cbab4c268b07bd8a28785aac4ec2e2642ee555328e291095f6500afab75945446477eef87457282ed1bdec4337a8dd5192dfa813dca0afa2c2acea9b39f4e1be785785261aba4cfab466859c287835470f3d76d0a6d04ff9a9dc771d326b6957beb0c50ab30745c6f13245b5d116ae1551b313087faddc440e7b176024bdf73436ae35b97e5b0b6a97a6fc3211c57a000bbfbefb1024234dd206115b546ec23ef8e77e70813d1e392ddf568661749b077f3a28b0b251bd7fb7c96d018d23d3f65ed0a36095722fede2084b59a20ffa3eaa3ce44769b9e023e33dc6821892a5ae2400382f164e43939faa69931022deecd7fa508f2996444f6753395e5d25a123685f37f7e04f6d7daf1b1da4679130b344f0073e06d49ad482f0cb7dd0d768aaf0cad53fee0d120cb47637c4486e9ed467390b773b6ba4246655c0291c4be63409d723369b0c7c093d48f0d812972fae1d66e5625d6850836919db591a3419ca57e16cec97147b5ebb5f9807f3759296ca2ef1927db4ce5da444d4dc50cbdb1d718fa2f96fb4db51f0517df37fc30352212cd7c1f31fc31cf0c46bb69dce277c64d237fa73aee1ca7aea66d0b8b8503a811ff71eb559437b3d903a536c87726825dc0203e88cd5c24b120b785833e53c025f27b2eef75f31bc1a8e791b9e9b6b9643c272dcd3487fc1b17a50870170bd3d5d651b48a7946856578680a85d42091ee3a35fe9756c9aa7fa3d326ac96ad8ad4bf30c3cee0790b8ca733d9c0c5e2e4c792a7c26d52ea24a8127f5eea530200685f7c62b304d4e6e6b4e3e1a46aeb79f78bc924069dc0009e2e1f683a748bd45da3a0a7e09d362d78b34a9a586b77d3d124f477cc8ba401b355db4c5973e1a9f1ac5e3ab66da1307ad74bc23a418b1b16dfcd7de9cb5049a843caa4e91e95e935493b059c4df045263f2ebea813cb0ab2fde74e4b99f5778886499c585254bc6e25876d75327cb21468c57b804042fe04a7e7f93d8fb4d686341148219c06159c877f508c53c66a2cb250d7f6da169caeb327401856e5ac7c674b25d5ab559d7c16ffb8394011a93ac47e49f8a37e5719a68bbda3957a9c28b867d2acda37e85ce121141894fd5e9e6e43e8744ff1f210e009273e96eadf8e271bacbd6b8cb3904ba0d3c53a7aed06df0fe36088e6218261848adae828a0463617c0ac5c9529f8416d1c5a857e003ada23c7ba6e4b9ee73fed0034bdc1732a918e5fc7d2816b6555b817055ec18285be3e0547695a2dd0d4c459e171e311637ca69d4a68c038db1e73f11011b622f593a62973010b8573e43bc7fb82b99d67e232a4c0e39a50162bb4d6cbccab56d55e75bb636f73c436d18751d2e0a06cafc7fa21a94c1dc55f86581ca8eebd5f7d8b3a8570833de4a793fb55808e4913d40ef817f47678a0e8a3add43644afb3c3cd9c9bf405b63c989276df613ddd70558e68e0cea54fd8c9ee5a93c96a5320c78e8371ccea865bebddc967353bd33f6a0267f8bf7b5ced2bc3058068411af135e16430872ab3c2e4bc0f1e466e8b9cccdcbd1ba55e7b5ee8814a66a060300afec1e1a476e3b4fd45de976b1bacdc564cb52e9e40ec12a5cf632a153dbd08f8b3e0ced41405527b39461046452d13212c6b3517b00265a2bc1d672672f6161e7897f24c04ee4191bc93a2a916475cc9dfb8ce83f47d8bb8e1bc7f1ad7ccbc359b5dfc4bc8d6fb4e1adacadccbfae29897d9361314fac61670cfe3b945d4c1da3aaa73c2a51b5474ae964bfee919bc3a46fa3506736ade79e5e12bc99c54fccdfbfb5963fc8b249c8269a7cfd4bb9d9542512368981ed613be6f8621b20e817d673ff309a9a0f8e501b961f0deb76def7b08113bb93e186514edf13c032c239528d1730db33b0422828b64e4b26f03c6ec3385c7e5526833e49d8e5ecca9d8e40374d4167149818513ab0c2f796ef22ecc9f67a4046b6f8296bea4f7ab1db42d4a0167ed3d4e94f036b7eb33c6c421b212d60fea5bffe938e1666cd7dbcf10d9a4deae07bba5b64426ae65c38ef2b080fbf479ffd9f7af91a24d8595a9e6acb108b9480a37a3731844be1a1d6e1c37257fb05e4000a94348f4808aa5582184b2fd08e7eeee6da44e03017d487b4f6b54ffa1f0b46e9028060d671938525e5d93207b068ed7c034c3d9fa091a2ee35080bdbaf5448b1ebf617aa105ceecb249247623f5c24594358e8907924778d48345bd9fd089cf3e6258a36c455172f9f1748cd3dbcededd74df7826d81f9c45f4cd99de0608efd6100cc1cbec3775804b0614873f4ec1ed330db4961ef979a260b1603ac707fef38acecf74731e3817625a5f949915b50240e8bbf93b072aec54966f9babe31be2f030cf7c41e9c921bb06b2cc971bb1dc83a451d9d984e6558b28cd9da0b873848e988f369c752df9ece76408f9c53e4dacf564b5ccbcdca14469ffe74ca984b89dbe6174332da699ac8aa98b68f55d287dfea02d59e39287593c719dd1b8f66f1705409481d1e8a67d860803b41c24d11cf71cabe3fdb84b6b522e5b68e4d004b017374e8b76c6b791f052a0d52200a72df3264dd100e46a46bf8984870c50cfd4fa586528bc89f35d550255d74a84f9afadbfa9b7ffb3981568facafed9e86f1e7ba3a6576188349e81811ba472a123a1eeb8fdbd0c6057d14d13e50cb7a5dbaa308234bde0dfbcd7393076a6290a3a4ae24ab007051274a2aaa81a7a98ca6a885ebea1d781e62e05f0cfa5b0e90f6e8c5494b9aee414518ebda32455acc00c066a1fed553424690ea0e6932082e5ef9d273eff61f669fe990bf16ac1e8332f15380d9601a77bb195b02dc25624f07bc797bb800cd16821980994ea4894c43c8685b607577cae6000c0546ade870e30f0e5f819135283790c3aa243cf4c679b4def7d230fff3635b7636707961f51d0854abb8fc07b8453eb41afdaf46ce2d39bbe3d5a0a3de5aa1bdc25fc2e5d501395780f73069b7d5cde3238da5acfe0483fb5b63f18767dd142f2a2b98ceb6760727df9d9289570c47b99497e33746dd3290e976813b8c3e34b79af6306be6cb678438585500783ac36af323733e40dc643f6bb8c0a6537b9c26707385fd9f3a5e41699907686e7d7abdf2a6b243ea841a7c343b22e84005420789776dc3aefd170cea30701f141509fb0d3308016b7f9bcd7bc042fc97a3ad1a9a8fd0bd51d3640e85b7c962acc582b4d59d1709f1a2f4da43561e00e23143c921654abe642da62f2634d617b27843b77c0134101e2cba0ae66a395e10d89a0acd3fe021dec7750c5ab6c3c3cac037de41ff482e10387d90d116089e968c00a6eb6584d489492cb51328207ccf7a29f6e549b66da4374430d2587387cf950eb7aa6585b3751a910960bf3df9207a2a63cd15b7be0877e8256d30e3eae7e9add2a7e378ae3f58728226227d4e44902a64d880b13824fa0695df047de25e236948f16b79811518b40f382b9ad744dce1be26d6befa9f1edb0462675433b648429961e86291b7d571889a69b4f16750628a0b9a896f7f71044d27f5f7dedf1c10f77c05e2469e454ce0e8fb468b2c5fdbe10efb59df8dc2eb1413c1abb9d4475e4f2168fb77dc8fbbdc9c27193bbee69cf1ff3deae57a0b9bc4ab647e5eec9c2a0b29e4cbc393abb0d4c8572eeb9c43c2d0e23bf74ece0a1f180e90a2b64f1603c0a0814ff7541f9e8b4de15ccd7d8aa8cc701cdfa5bbdabe551876271d07604ba370b401fab8bfc0f331d74128406c8f77381c760bdd6b13b9a9da9e76ae3c860413091c2512c707bfcb28a6830cad64e31c46deaff8ee36d23bf377d15cefa7791a66e72d1d98a51ec4111564533c8b170849ca14d4e123e233182fe5e100f86a85ac91a789c7b2244f57963e97ae7804e09e050d3ab3458fa2ea53ad03c28ba015586f7cbaa534ba7ce6f97e720026192ecb022d78e187a0f5ef986be6e25299c156505ec4069b5d9c26b9395d694a36548eb59f0e501e1fbce7fc5808ce53969691ab52ef08f041c19403e6788d26d617db4503c1c7dc24454ada3161ab3bc2200914c5a8412a4cea1dc02088c8817f95b52a374655ca39b98ec1ed6982ae8c995d9de41de9a2798a5cd</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Hey, password is required here.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 收集 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 诗词歌赋 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World！</title>
      <link href="/2023/09/04/hello%20world/"/>
      <url>/2023/09/04/hello%20world/</url>
      
        <content type="html"><![CDATA[<h1>建站起因</h1><p>突然发现自己已经是大三老东西了，前两年由于兴趣广泛，试了不少错，遍尝失败苦果，现在已经没有试错的资本了。之前学长说我涉猎多而不精，现在想来也是，我总是见猎心喜，打算学习某方面知识然后又浅尝辄止，且由于能力精力有限，导致了如今反省自身只能惶恐地发现竟无一项所长，可供我在激烈竞争中脱颖而出。未来方向之多以致惊慌迷茫失措，我也该思考未来规划了（这也许是我第一次面临这样的选择，从小到大，升学、分科、择校、转专业种种选择，我仿佛都在随波逐流，从未独立作出自己的抉择）</p><p>之前见过同学的博客，我也心血来潮跟着教程折腾了几天，搭建了个自己的博客（hexo+butterfly 确实简单易用且美观），希望以此记录我的学习轨迹，兼作督促。</p><h1>未来规划</h1><p>博客先就这样了(虽然还有不少问题没有解决和好多功能没有实现)，其实我对美观方面是比较在意的，先立个 flag，以后有时间的话一定回来继续优化。</p><p>新的学年不能再像之前那般任性且遇难则退，希望能选定一个方向进行深耕，做到精通。学习轨迹我也会尽量更新在本博客 😉</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生活 </tag>
            
            <tag> 杂谈 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
